{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "20NewsAnalysis.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "HbLHIzOojlZT",
    "colab_type": "code",
    "outputId": "ef7f0d2b-9797-4bd7-acdc-70a74cd6da0f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    }
   },
   "source": [
    "!pip install -U spacy\n",
    "\n",
    "# download english vocab\n",
    "!python -m spacy download en_core_web_sm"
   ],
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: spacy in /usr/local/lib/python3.6/dist-packages (2.2.2)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy) (0.23)\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied, skipping upgrade: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (41.4.0)\n",
      "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.17.4)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.28.1)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->spacy) (7.2.0)\n",
      "Requirement already satisfied: en_core_web_sm==2.2.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz#egg=en_core_web_sm==2.2.0 in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
      "Requirement already satisfied: spacy>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.0) (2.2.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (2.21.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.9.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (2.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.23)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.2.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (7.3.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (41.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.17.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy>=2.2.0->en_core_web_sm==2.2.0) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (4.28.1)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->spacy>=2.2.0->en_core_web_sm==2.2.0) (7.2.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djkwkqH17v6E",
    "colab_type": "text"
   },
   "source": [
    "# Introduction \n",
    "\n",
    "This kernel has been made to study 4 things :\n",
    "\n",
    "* compare the precision of Doc2Vec vs TF-IDF \n",
    "\n",
    "* Determine if stemming have an impact on performance of the model. If it's improve the scores or decrease the score. We know that stemming is used to reduce the size of the vocabulary to speed the training. But if it's reduce  the vocabulary  and in the same time reduce the accuracy we need to know at what level. \n",
    "\n",
    "* Determine the size of the dataset. Size from which our model provided good results. How many words? The size of the vocabulary.\n",
    "\n",
    "* What is the best simple models that perform good on big and tiny dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "FjLeutDlbFus",
    "colab": {}
   },
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxCng5X5gTS1",
    "colab_type": "text"
   },
   "source": [
    "The aim of this project is to study the performance of TF-IDF VS Doc2Vec. \n",
    "We are going to use 4 modèles to compare them :\n",
    "\n",
    "* LinearSVC \n",
    "* XGboost \n",
    "* Logistic-regression \n",
    "* Naives-bayes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "madp-QFxgRkX",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn  as sns \n",
    "import matplotlib.pyplot as plt "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5HvSuJI1gv55",
    "colab_type": "code",
    "outputId": "22868894-ecfe-4017-db1c-9815abae7808",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    }
   },
   "source": [
    "newsgroups_train.data[0]"
   ],
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 51
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6B9gNxY5KWj",
    "colab_type": "text"
   },
   "source": [
    "# Study the dataset \n",
    "\n",
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIUzW7HhspzY",
    "colab_type": "text"
   },
   "source": [
    "## Distrubution "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zBIAbGseuBDl",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def displayFeaturesAndDescribe(array_features, feature, kind='bar', color=None):\n",
    "    s = pd.Series(array_features)\n",
    "    feature_count = (s.value_counts() /s.shape[0]) * 100\n",
    "    feature_dataframe = pd.DataFrame()\n",
    "    feature_dataframe[feature] = feature_count.index\n",
    "    feature_dataframe['Percentage'] = feature_count.values\n",
    "    sns.catplot(x=feature, y='Percentage', kind=kind, data=feature_dataframe, hue='Percentage', aspect=2, height=5,legend_out=True)\n",
    "    "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Lp7ZSh3nvJ2Y",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Fap0qe4WvYIR",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "outputId": "7fa913ca-5de0-4ffa-91ed-44bac84aa435"
   },
   "source": [
    "target_df = pd.DataFrame({'target_name' : newsgroups_train.target_names,  'target_value' :np.unique(newsgroups_train.target)})\n",
    "target_df "
   ],
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_name</th>\n",
       "      <th>target_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comp.windows.x</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sci.space</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>talk.politics.misc</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 target_name  target_value\n",
       "0                alt.atheism             0\n",
       "1              comp.graphics             1\n",
       "2    comp.os.ms-windows.misc             2\n",
       "3   comp.sys.ibm.pc.hardware             3\n",
       "4      comp.sys.mac.hardware             4\n",
       "5             comp.windows.x             5\n",
       "6               misc.forsale             6\n",
       "7                  rec.autos             7\n",
       "8            rec.motorcycles             8\n",
       "9         rec.sport.baseball             9\n",
       "10          rec.sport.hockey            10\n",
       "11                 sci.crypt            11\n",
       "12           sci.electronics            12\n",
       "13                   sci.med            13\n",
       "14                 sci.space            14\n",
       "15    soc.religion.christian            15\n",
       "16        talk.politics.guns            16\n",
       "17     talk.politics.mideast            17\n",
       "18        talk.politics.misc            18\n",
       "19        talk.religion.misc            19"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 53
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zMstXkc6xohe",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "outputId": "9ec38fe9-8b14-48b6-9890-92a5a333008d"
   },
   "source": [
    "target_serie = pd.Series(newsgroups_train.target)\n",
    "target_df['distribution'] = target_serie.value_counts()/target_serie.count() * 100\n",
    "target_df"
   ],
   "execution_count": 54,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_name</th>\n",
       "      <th>target_value</th>\n",
       "      <th>distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>0</td>\n",
       "      <td>4.242531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>1</td>\n",
       "      <td>5.161747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>2</td>\n",
       "      <td>5.223617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>3</td>\n",
       "      <td>5.214778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>4</td>\n",
       "      <td>5.108715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comp.windows.x</td>\n",
       "      <td>5</td>\n",
       "      <td>5.241294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>6</td>\n",
       "      <td>5.170585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>7</td>\n",
       "      <td>5.250133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>8</td>\n",
       "      <td>5.285487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>9</td>\n",
       "      <td>5.276648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>10</td>\n",
       "      <td>5.303164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>11</td>\n",
       "      <td>5.258971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>12</td>\n",
       "      <td>5.223617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>13</td>\n",
       "      <td>5.250133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sci.space</td>\n",
       "      <td>14</td>\n",
       "      <td>5.241294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>15</td>\n",
       "      <td>5.294326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>16</td>\n",
       "      <td>4.825879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>17</td>\n",
       "      <td>4.984974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>talk.politics.misc</td>\n",
       "      <td>18</td>\n",
       "      <td>4.109952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>19</td>\n",
       "      <td>3.332155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 target_name  target_value  distribution\n",
       "0                alt.atheism             0      4.242531\n",
       "1              comp.graphics             1      5.161747\n",
       "2    comp.os.ms-windows.misc             2      5.223617\n",
       "3   comp.sys.ibm.pc.hardware             3      5.214778\n",
       "4      comp.sys.mac.hardware             4      5.108715\n",
       "5             comp.windows.x             5      5.241294\n",
       "6               misc.forsale             6      5.170585\n",
       "7                  rec.autos             7      5.250133\n",
       "8            rec.motorcycles             8      5.285487\n",
       "9         rec.sport.baseball             9      5.276648\n",
       "10          rec.sport.hockey            10      5.303164\n",
       "11                 sci.crypt            11      5.258971\n",
       "12           sci.electronics            12      5.223617\n",
       "13                   sci.med            13      5.250133\n",
       "14                 sci.space            14      5.241294\n",
       "15    soc.religion.christian            15      5.294326\n",
       "16        talk.politics.guns            16      4.825879\n",
       "17     talk.politics.mideast            17      4.984974\n",
       "18        talk.politics.misc            18      4.109952\n",
       "19        talk.religion.misc            19      3.332155"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 54
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fBJkJvRDuDBW",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "outputId": "a36a0ea6-6cde-48a8-ae9b-54402ce12a21"
   },
   "source": [
    "displayFeaturesAndDescribe(array_features=newsgroups_train.target, feature='labels')"
   ],
   "execution_count": 55,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAAFgCAYAAACi3Ah8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 867.25x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aSlsxPCczIc9",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "outputId": "e32db63a-78ed-4e78-b9fc-de6ab7e751fc"
   },
   "source": [
    "target_df['distribution'].describe()"
   ],
   "execution_count": 56,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    20.000000\n",
       "mean      5.000000\n",
       "std       0.514865\n",
       "min       3.332155\n",
       "25%       5.077780\n",
       "50%       5.223617\n",
       "75%       5.252342\n",
       "max       5.303164\n",
       "Name: distribution, dtype: float64"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 56
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eol5YL79yN-7",
    "colab_type": "text"
   },
   "source": [
    "The dataset is well balanced. The percentage of each class is approximatly of 5%. Religion is represented at 3.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdXWmelBinRp",
    "colab_type": "text"
   },
   "source": [
    "# Clean the data \n",
    "\n",
    "The first step we are going to use spacy to clean the data by :\n",
    "\n",
    "* lower all the word to avoid that word like : Hello HELLO or hello are \n",
    "considered as 3 differents words.\n",
    "* removing stop words \n",
    "* removing punctuation \n",
    "* lemming \n",
    "\n",
    "\n",
    "Note : In the second part we will do the same without lemming to see the performance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gSQtZTjSjhn5",
    "colab_type": "code",
    "outputId": "801589bd-d463-480e-ab7c-8f43dd8cb29a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "import spacy\n",
    "\n",
    "print('spaCy Version: %s' % (spacy.__version__))\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = spacy.lang.en.STOP_WORDS\n",
    "punctuations = spacy.lang.punctuation.PUNCT"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "spaCy Version: 2.2.2\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MByuTvAklBCr",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "parse = spacy_nlp(newsgroups_train.data[0])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Dsfis5SRl2jK",
    "colab_type": "code",
    "outputId": "77670a6b-66a4-4048-ace7-d00995eb079c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "parse.vocab.length"
   ],
   "execution_count": 59,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "572"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 59
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjnJpu_smTLY",
    "colab_type": "text"
   },
   "source": [
    "Spacy parser, parse the text and apply different model on the text :\n",
    "\n",
    "* Tokenizer : Split the text in token. (base on the language)\n",
    "* NER => identify entity in the text \n",
    "* Tagger => Assign part-of-speech tags.\n",
    "* TextCat => optionnal you can add a text classifier "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XRRzQwLLqvDn",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# create a copy of the dataset \n",
    "x_train = newsgroups_train.data.copy()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eoe-8ovVkFv6",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "def prepareText(text):\n",
    "  \"\"\"\n",
    "  This function clean the text. \n",
    "  \"\"\"\n",
    "\n",
    "  processing = spacy_nlp(text)\n",
    "  \n",
    "  # lowering words and lemming \n",
    "  # strip space \n",
    "  # don't apply lemming if the word is a pronoun because spacy convert the word in \"-PRON-\" and we need all the word \n",
    "  processing = [ word.lemma_.lower() if word.lemma_ != \"-PRON-\" else word.lower_ for word in processing ] \n",
    "\n",
    "  # remove stop words and punctuation \n",
    "\n",
    "  processing = [word  for word in processing if (word not in stop_words and punctuations)]\n",
    "\n",
    "  return processing  "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvfZXx5jsq_x",
    "colab_type": "text"
   },
   "source": [
    "We will implement the same function but without lemming. We could add a boolean variable to indicate if we do lemming or not but for performance reason I prefer to implement an other function.\n",
    "\n",
    "Let's test this one "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kIoD-N-EtANV",
    "colab_type": "code",
    "outputId": "bc214fd9-9f5e-4bf7-9506-63237833b70b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "prepareText(x_train[0])"
   ],
   "execution_count": 62,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[':',\n",
       " 'lerxst@wam.umd.edu',\n",
       " '(',\n",
       " 'thing',\n",
       " ')',\n",
       " '\\n',\n",
       " 'subject',\n",
       " ':',\n",
       " 'car',\n",
       " '!',\n",
       " '?',\n",
       " '\\n',\n",
       " 'nntp',\n",
       " '-',\n",
       " 'posting',\n",
       " '-',\n",
       " 'host',\n",
       " ':',\n",
       " 'rac3.wam.umd.edu',\n",
       " '\\n',\n",
       " 'organization',\n",
       " ':',\n",
       " 'university',\n",
       " 'maryland',\n",
       " ',',\n",
       " 'college',\n",
       " 'park',\n",
       " '\\n',\n",
       " 'line',\n",
       " ':',\n",
       " '15',\n",
       " '\\n\\n ',\n",
       " 'wonder',\n",
       " 'enlighten',\n",
       " 'car',\n",
       " '\\n',\n",
       " 'day',\n",
       " '.',\n",
       " '2-door',\n",
       " 'sport',\n",
       " 'car',\n",
       " ',',\n",
       " 'look',\n",
       " 'late',\n",
       " '60s/',\n",
       " '\\n',\n",
       " 'early',\n",
       " '70',\n",
       " '.',\n",
       " 'bricklin',\n",
       " '.',\n",
       " 'door',\n",
       " 'small',\n",
       " '.',\n",
       " 'addition',\n",
       " ',',\n",
       " '\\n',\n",
       " 'bumper',\n",
       " 'separate',\n",
       " 'rest',\n",
       " 'body',\n",
       " '.',\n",
       " '\\n',\n",
       " 'know',\n",
       " '.',\n",
       " 'tellme',\n",
       " 'model',\n",
       " ',',\n",
       " 'engine',\n",
       " 'spec',\n",
       " ',',\n",
       " 'year',\n",
       " '\\n',\n",
       " 'production',\n",
       " ',',\n",
       " 'car',\n",
       " ',',\n",
       " 'history',\n",
       " ',',\n",
       " 'info',\n",
       " '\\n',\n",
       " 'funky',\n",
       " 'look',\n",
       " 'car',\n",
       " ',',\n",
       " 'e',\n",
       " '-',\n",
       " 'mail',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'thank',\n",
       " ',',\n",
       " '\\n',\n",
       " '-',\n",
       " 'il',\n",
       " '\\n   ',\n",
       " '----',\n",
       " 'bring',\n",
       " 'neighborhood',\n",
       " 'lerxst',\n",
       " '----',\n",
       " '\\n\\n\\n\\n\\n']"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 62
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9_2PzEEOvMb1",
    "colab_type": "code",
    "outputId": "1c3dcc1d-8165-483d-ca52-2539f0af9011",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "\n",
    "for i in range(0, len(x_train)) :\n",
    "  x_train[i] = prepareText(x_train[i])\n",
    "\n",
    "x_train[0]"
   ],
   "execution_count": 63,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[':',\n",
       " 'lerxst@wam.umd.edu',\n",
       " '(',\n",
       " 'thing',\n",
       " ')',\n",
       " '\\n',\n",
       " 'subject',\n",
       " ':',\n",
       " 'car',\n",
       " '!',\n",
       " '?',\n",
       " '\\n',\n",
       " 'nntp',\n",
       " '-',\n",
       " 'posting',\n",
       " '-',\n",
       " 'host',\n",
       " ':',\n",
       " 'rac3.wam.umd.edu',\n",
       " '\\n',\n",
       " 'organization',\n",
       " ':',\n",
       " 'university',\n",
       " 'maryland',\n",
       " ',',\n",
       " 'college',\n",
       " 'park',\n",
       " '\\n',\n",
       " 'line',\n",
       " ':',\n",
       " '15',\n",
       " '\\n\\n ',\n",
       " 'wonder',\n",
       " 'enlighten',\n",
       " 'car',\n",
       " '\\n',\n",
       " 'day',\n",
       " '.',\n",
       " '2-door',\n",
       " 'sport',\n",
       " 'car',\n",
       " ',',\n",
       " 'look',\n",
       " 'late',\n",
       " '60s/',\n",
       " '\\n',\n",
       " 'early',\n",
       " '70',\n",
       " '.',\n",
       " 'bricklin',\n",
       " '.',\n",
       " 'door',\n",
       " 'small',\n",
       " '.',\n",
       " 'addition',\n",
       " ',',\n",
       " '\\n',\n",
       " 'bumper',\n",
       " 'separate',\n",
       " 'rest',\n",
       " 'body',\n",
       " '.',\n",
       " '\\n',\n",
       " 'know',\n",
       " '.',\n",
       " 'tellme',\n",
       " 'model',\n",
       " ',',\n",
       " 'engine',\n",
       " 'spec',\n",
       " ',',\n",
       " 'year',\n",
       " '\\n',\n",
       " 'production',\n",
       " ',',\n",
       " 'car',\n",
       " ',',\n",
       " 'history',\n",
       " ',',\n",
       " 'info',\n",
       " '\\n',\n",
       " 'funky',\n",
       " 'look',\n",
       " 'car',\n",
       " ',',\n",
       " 'e',\n",
       " '-',\n",
       " 'mail',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'thank',\n",
       " ',',\n",
       " '\\n',\n",
       " '-',\n",
       " 'il',\n",
       " '\\n   ',\n",
       " '----',\n",
       " 'bring',\n",
       " 'neighborhood',\n",
       " 'lerxst',\n",
       " '----',\n",
       " '\\n\\n\\n\\n\\n']"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 63
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBFa3RLr3WLd",
    "colab_type": "text"
   },
   "source": [
    "# TF-IDF \n",
    "\n",
    "Once our training data have been cleaned we need to apply countVectorizer to the dataset. \n",
    "\n",
    "CountVectorizer will tranform each ext to a sparse matrix that represent words frequency in the text. Then we will be able to apply TF-IDF on this sparse matrix. \n",
    "\n",
    "Tf_IDF : this algorithm use word frequency in a document and the word frequency in other document to compute a value that represent the word in the document. The more a word appear the least this value will be high. \n",
    "It's determine the more relevant word in a text. The important word. \n",
    "\n",
    "The intuition is that word that are important are not repeated frequently in a document.\n",
    "\n",
    "## CountVectorizer \n",
    "\n",
    "Here by doing ‘count_vect.fit_transform(twenty_train.data)’, we are learning the vocabulary dictionary and it returns a Document-Term matrix. [n_samples, n_features]."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "prGMQrwb3VSq",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "count_vec = CountVectorizer()\n",
    "cv_data = count_vec.fit_transform(newsgroups_train.data)\n",
    "tfidf = TfidfTransformer()\n",
    "tfidf_data = tfidf.fit_transform(cv_data)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WKUG1rlmB1xd",
    "colab_type": "code",
    "outputId": "89322ab8-5045-4f70-d74f-7b1c08716ed2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "tfidf_data.shape"
   ],
   "execution_count": 65,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 65
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mbsTjGp5CB6V",
    "colab_type": "code",
    "outputId": "587138cd-3dce-41f3-d70f-dd950312c2d4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "newsgroups_train.target.shape"
   ],
   "execution_count": 66,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 66
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "urMtoDRpzE2M",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import numpy as np \n",
    "classes = np.unique(newsgroups_train.target)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kK65H_Oc45cf",
    "colab_type": "text"
   },
   "source": [
    "The different class name in the dataset are :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SJloGtbn5BmB",
    "colab_type": "code",
    "outputId": "bb581449-9efe-4824-8028-62b4170bb5d9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    }
   },
   "source": [
    "newsgroups_train.target_names"
   ],
   "execution_count": 68,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 68
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AB09rxPDEQB4",
    "colab_type": "text"
   },
   "source": [
    "Each row represent a document of dataset.\n",
    "\n",
    "#training \n",
    "\n",
    "We can now train our 4 modeles on the TF-IDF matrix now that we have a representation of all the document. We need to train our modele to predict a input text class base using the TF-IDF matrix. \n",
    "\n",
    "\n",
    "We are going to create a pipeline for each one :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HfimCUDUEauV",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import seaborn as sns \n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xVKEbY5iFIUM",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "naives_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB())])\n",
    "log_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LogisticRegression())])\n",
    "sgd_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', SGDClassifier())]) \n",
    "svc_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LinearSVC())])\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmOXUZaH-8QP",
    "colab_type": "text"
   },
   "source": [
    "### classification_report : \n",
    "\n",
    "Compute precision, recall, F-measure and support for each class\n",
    "\n",
    "* The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "* The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "* precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "* The support is the number of occurrences of each class in y_true."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yxoJLwlHIqlx",
    "colab_type": "code",
    "outputId": "5a8c1e89-59d0-4993-d57d-f690cde754e4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "from sklearn.metrics import classification_report\n",
    "modeles = {\"naives\":naives_clf, \"logistic regression\": log_clf, \"SGD_classifier\":sgd_clf, \"Linear SVC\":svc_clf}\n",
    "\n",
    "\n",
    "for key in modeles:\n",
    "  modeles[key].fit(newsgroups_train.data, newsgroups_train.target)\n",
    "  predicted = modeles[key].predict(newsgroups_test.data)\n",
    "  score = classification_report(y_pred=predicted, y_true=newsgroups_test.target, labels=classes)\n",
    "  print(f\"Modele : {key} score : {score} \\n\\n\\n\")"
   ],
   "execution_count": 71,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Modele : naives score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.52      0.63       319\n",
      "           1       0.81      0.65      0.72       389\n",
      "           2       0.82      0.65      0.73       394\n",
      "           3       0.67      0.78      0.72       392\n",
      "           4       0.86      0.77      0.81       385\n",
      "           5       0.89      0.75      0.82       395\n",
      "           6       0.93      0.69      0.80       390\n",
      "           7       0.85      0.92      0.88       396\n",
      "           8       0.94      0.93      0.93       398\n",
      "           9       0.92      0.90      0.91       397\n",
      "          10       0.89      0.97      0.93       399\n",
      "          11       0.59      0.97      0.74       396\n",
      "          12       0.84      0.60      0.70       393\n",
      "          13       0.92      0.74      0.82       396\n",
      "          14       0.84      0.89      0.87       394\n",
      "          15       0.44      0.98      0.61       398\n",
      "          16       0.64      0.94      0.76       364\n",
      "          17       0.93      0.91      0.92       376\n",
      "          18       0.96      0.42      0.58       310\n",
      "          19       0.97      0.14      0.24       251\n",
      "\n",
      "    accuracy                           0.77      7532\n",
      "   macro avg       0.83      0.76      0.76      7532\n",
      "weighted avg       0.82      0.77      0.77      7532\n",
      " \n",
      "\n",
      "\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Modele : logistic regression score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       319\n",
      "           1       0.69      0.78      0.74       389\n",
      "           2       0.76      0.75      0.75       394\n",
      "           3       0.73      0.72      0.72       392\n",
      "           4       0.81      0.83      0.82       385\n",
      "           5       0.83      0.74      0.78       395\n",
      "           6       0.76      0.90      0.83       390\n",
      "           7       0.91      0.89      0.90       396\n",
      "           8       0.94      0.95      0.94       398\n",
      "           9       0.87      0.93      0.90       397\n",
      "          10       0.94      0.96      0.95       399\n",
      "          11       0.93      0.89      0.91       396\n",
      "          12       0.76      0.78      0.77       393\n",
      "          13       0.89      0.84      0.86       396\n",
      "          14       0.89      0.92      0.91       394\n",
      "          15       0.79      0.93      0.85       398\n",
      "          16       0.71      0.90      0.80       364\n",
      "          17       0.96      0.89      0.92       376\n",
      "          18       0.79      0.58      0.67       310\n",
      "          19       0.83      0.45      0.59       251\n",
      "\n",
      "    accuracy                           0.83      7532\n",
      "   macro avg       0.83      0.82      0.82      7532\n",
      "weighted avg       0.83      0.83      0.83      7532\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Modele : SGD_classifier score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.79       319\n",
      "           1       0.78      0.79      0.78       389\n",
      "           2       0.75      0.74      0.74       394\n",
      "           3       0.72      0.76      0.74       392\n",
      "           4       0.84      0.85      0.84       385\n",
      "           5       0.88      0.76      0.82       395\n",
      "           6       0.83      0.91      0.87       390\n",
      "           7       0.93      0.90      0.92       396\n",
      "           8       0.95      0.95      0.95       398\n",
      "           9       0.92      0.95      0.93       397\n",
      "          10       0.95      0.98      0.97       399\n",
      "          11       0.91      0.95      0.93       396\n",
      "          12       0.83      0.79      0.81       393\n",
      "          13       0.89      0.89      0.89       396\n",
      "          14       0.89      0.94      0.92       394\n",
      "          15       0.82      0.93      0.87       398\n",
      "          16       0.74      0.93      0.82       364\n",
      "          17       0.96      0.91      0.94       376\n",
      "          18       0.88      0.61      0.72       310\n",
      "          19       0.76      0.57      0.65       251\n",
      "\n",
      "    accuracy                           0.85      7532\n",
      "   macro avg       0.85      0.84      0.85      7532\n",
      "weighted avg       0.85      0.85      0.85      7532\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Modele : Linear SVC score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       319\n",
      "           1       0.76      0.80      0.78       389\n",
      "           2       0.77      0.73      0.75       394\n",
      "           3       0.71      0.76      0.74       392\n",
      "           4       0.84      0.86      0.85       385\n",
      "           5       0.87      0.76      0.81       395\n",
      "           6       0.83      0.91      0.87       390\n",
      "           7       0.92      0.91      0.91       396\n",
      "           8       0.95      0.95      0.95       398\n",
      "           9       0.92      0.95      0.93       397\n",
      "          10       0.96      0.98      0.97       399\n",
      "          11       0.93      0.94      0.93       396\n",
      "          12       0.81      0.79      0.80       393\n",
      "          13       0.90      0.87      0.88       396\n",
      "          14       0.90      0.93      0.92       394\n",
      "          15       0.84      0.93      0.88       398\n",
      "          16       0.75      0.92      0.82       364\n",
      "          17       0.97      0.89      0.93       376\n",
      "          18       0.82      0.62      0.71       310\n",
      "          19       0.75      0.61      0.68       251\n",
      "\n",
      "    accuracy                           0.85      7532\n",
      "   macro avg       0.85      0.85      0.85      7532\n",
      "weighted avg       0.85      0.85      0.85      7532\n",
      " \n",
      "\n",
      "\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iSy0gfJJOdL",
    "colab_type": "text"
   },
   "source": [
    "F1-score and Precision"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-VFCXfitJrGP",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "naives_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB())])\n",
    "log_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LogisticRegression())])\n",
    "sgd_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', SGDClassifier())]) \n",
    "svc_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LinearSVC())])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Pmbd3UfrJt6R",
    "colab_type": "code",
    "outputId": "ad5d19ce-ae7b-412d-c4fd-4e914c9eb527",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "from sklearn.metrics import classification_report\n",
    "modeles = {\"naives\":naives_clf, \"logistic regression\": log_clf, \"SGD_classifier\":sgd_clf, \"Linear SVC\":svc_clf}\n",
    "\n",
    "\n",
    "for key in modeles:\n",
    "  modeles[key].fit(newsgroups_train.data, newsgroups_train.target)\n",
    "  predicted = modeles[key].predict(newsgroups_test.data)\n",
    "  score = classification_report(y_pred=predicted, y_true=newsgroups_test.target, labels=classes)\n",
    "  print(f\"Modele : {key} score : {score} \\n\\n\\n\")"
   ],
   "execution_count": 73,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Modele : naives score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.69      0.74       319\n",
      "           1       0.78      0.72      0.75       389\n",
      "           2       0.79      0.72      0.75       394\n",
      "           3       0.68      0.81      0.74       392\n",
      "           4       0.86      0.81      0.84       385\n",
      "           5       0.87      0.78      0.82       395\n",
      "           6       0.87      0.80      0.83       390\n",
      "           7       0.88      0.91      0.90       396\n",
      "           8       0.93      0.96      0.95       398\n",
      "           9       0.91      0.92      0.92       397\n",
      "          10       0.88      0.98      0.93       399\n",
      "          11       0.75      0.96      0.84       396\n",
      "          12       0.84      0.65      0.74       393\n",
      "          13       0.92      0.79      0.85       396\n",
      "          14       0.82      0.94      0.88       394\n",
      "          15       0.62      0.96      0.76       398\n",
      "          16       0.66      0.95      0.78       364\n",
      "          17       0.95      0.94      0.94       376\n",
      "          18       0.94      0.52      0.67       310\n",
      "          19       0.95      0.24      0.38       251\n",
      "\n",
      "    accuracy                           0.82      7532\n",
      "   macro avg       0.84      0.80      0.80      7532\n",
      "weighted avg       0.83      0.82      0.81      7532\n",
      " \n",
      "\n",
      "\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Modele : logistic regression score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.72      0.75       319\n",
      "           1       0.71      0.79      0.75       389\n",
      "           2       0.75      0.76      0.75       394\n",
      "           3       0.71      0.71      0.71       392\n",
      "           4       0.80      0.82      0.81       385\n",
      "           5       0.84      0.75      0.79       395\n",
      "           6       0.78      0.87      0.82       390\n",
      "           7       0.90      0.89      0.89       396\n",
      "           8       0.93      0.95      0.94       398\n",
      "           9       0.88      0.92      0.90       397\n",
      "          10       0.93      0.96      0.94       399\n",
      "          11       0.95      0.91      0.93       396\n",
      "          12       0.74      0.78      0.76       393\n",
      "          13       0.88      0.86      0.87       396\n",
      "          14       0.88      0.91      0.90       394\n",
      "          15       0.80      0.93      0.86       398\n",
      "          16       0.74      0.90      0.81       364\n",
      "          17       0.97      0.89      0.93       376\n",
      "          18       0.85      0.58      0.69       310\n",
      "          19       0.81      0.49      0.61       251\n",
      "\n",
      "    accuracy                           0.83      7532\n",
      "   macro avg       0.83      0.82      0.82      7532\n",
      "weighted avg       0.83      0.83      0.83      7532\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Modele : SGD_classifier score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79       319\n",
      "           1       0.75      0.80      0.78       389\n",
      "           2       0.76      0.74      0.75       394\n",
      "           3       0.72      0.73      0.72       392\n",
      "           4       0.83      0.85      0.84       385\n",
      "           5       0.87      0.77      0.82       395\n",
      "           6       0.82      0.90      0.86       390\n",
      "           7       0.92      0.90      0.91       396\n",
      "           8       0.95      0.96      0.96       398\n",
      "           9       0.91      0.94      0.93       397\n",
      "          10       0.95      0.98      0.96       399\n",
      "          11       0.93      0.95      0.94       396\n",
      "          12       0.81      0.78      0.80       393\n",
      "          13       0.91      0.88      0.89       396\n",
      "          14       0.90      0.94      0.92       394\n",
      "          15       0.84      0.93      0.89       398\n",
      "          16       0.73      0.93      0.82       364\n",
      "          17       0.96      0.90      0.93       376\n",
      "          18       0.84      0.61      0.70       310\n",
      "          19       0.77      0.60      0.68       251\n",
      "\n",
      "    accuracy                           0.85      7532\n",
      "   macro avg       0.85      0.84      0.84      7532\n",
      "weighted avg       0.85      0.85      0.85      7532\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Modele : Linear SVC score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80       319\n",
      "           1       0.74      0.81      0.78       389\n",
      "           2       0.77      0.74      0.75       394\n",
      "           3       0.71      0.75      0.73       392\n",
      "           4       0.82      0.85      0.84       385\n",
      "           5       0.87      0.76      0.81       395\n",
      "           6       0.83      0.89      0.86       390\n",
      "           7       0.92      0.90      0.91       396\n",
      "           8       0.96      0.96      0.96       398\n",
      "           9       0.91      0.94      0.92       397\n",
      "          10       0.96      0.98      0.97       399\n",
      "          11       0.93      0.94      0.94       396\n",
      "          12       0.79      0.77      0.78       393\n",
      "          13       0.90      0.86      0.88       396\n",
      "          14       0.90      0.93      0.91       394\n",
      "          15       0.85      0.94      0.89       398\n",
      "          16       0.75      0.91      0.82       364\n",
      "          17       0.98      0.89      0.93       376\n",
      "          18       0.85      0.62      0.72       310\n",
      "          19       0.75      0.63      0.68       251\n",
      "\n",
      "    accuracy                           0.85      7532\n",
      "   macro avg       0.85      0.84      0.84      7532\n",
      "weighted avg       0.85      0.85      0.85      7532\n",
      " \n",
      "\n",
      "\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaXHaXQ3KOMu",
    "colab_type": "text"
   },
   "source": [
    "### With Stemming \n",
    "\n",
    "We herit from CountVectorizer and we apply stemming to each words in the \n",
    "text. We use NLTK for the stemming with the english vocab.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dVnu0SIRmEmY",
    "colab_type": "code",
    "outputId": "52835326-5262-48dd-fda2-d1370cf07a1b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    }
   },
   "source": [
    "!pip install nltk"
   ],
   "execution_count": 74,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AuqOgBrZKRwD",
    "colab_type": "code",
    "outputId": "711667d6-56c3-4093-c333-e4976f5cf881",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    }
   },
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])"
   ],
   "execution_count": 75,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HvRFPXwoKwjR",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "naives_clf = Pipeline([('vect', StemmedCountVectorizer(stop_words='english')),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('clf', MultinomialNB())])\n",
    "log_clf = Pipeline([('vect', StemmedCountVectorizer(stop_words='english')),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LogisticRegression())])\n",
    "sgd_clf = Pipeline([('vect', StemmedCountVectorizer(stop_words='english')),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', SGDClassifier())]) \n",
    "svc_clf = Pipeline([('vect', StemmedCountVectorizer(stop_words='english')),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LinearSVC())])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SKPWkjehK8dC",
    "colab_type": "code",
    "outputId": "f2974e0d-b942-4c7c-bdcf-c21d9ca21921",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "from sklearn.metrics import classification_report\n",
    "modeles = {\"naives\":naives_clf, \"logistic regression\": log_clf, \"SGD_classifier\":sgd_clf, \"Linear SVC\":svc_clf}\n",
    "\n",
    "\n",
    "for key in modeles:\n",
    "  modeles[key].fit(newsgroups_train.data, newsgroups_train.target)\n",
    "  predicted = modeles[key].predict(newsgroups_test.data)\n",
    "  score = classification_report(y_pred=predicted, y_true=newsgroups_test.target, labels=classes)\n",
    "  print(f\"Modele : {key} score : {score} \\n\\n\\n\")"
   ],
   "execution_count": 77,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Modele : naives score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.66      0.73       319\n",
      "           1       0.78      0.72      0.75       389\n",
      "           2       0.82      0.69      0.75       394\n",
      "           3       0.69      0.80      0.74       392\n",
      "           4       0.86      0.82      0.84       385\n",
      "           5       0.86      0.79      0.83       395\n",
      "           6       0.88      0.75      0.81       390\n",
      "           7       0.87      0.93      0.90       396\n",
      "           8       0.92      0.96      0.94       398\n",
      "           9       0.93      0.92      0.92       397\n",
      "          10       0.90      0.98      0.94       399\n",
      "          11       0.71      0.97      0.82       396\n",
      "          12       0.83      0.66      0.73       393\n",
      "          13       0.92      0.79      0.85       396\n",
      "          14       0.82      0.94      0.88       394\n",
      "          15       0.60      0.97      0.74       398\n",
      "          16       0.65      0.94      0.77       364\n",
      "          17       0.92      0.94      0.93       376\n",
      "          18       0.94      0.48      0.64       310\n",
      "          19       0.95      0.22      0.35       251\n",
      "\n",
      "    accuracy                           0.81      7532\n",
      "   macro avg       0.83      0.80      0.79      7532\n",
      "weighted avg       0.83      0.81      0.80      7532\n",
      " \n",
      "\n",
      "\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Modele : logistic regression score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74       319\n",
      "           1       0.72      0.80      0.76       389\n",
      "           2       0.76      0.76      0.76       394\n",
      "           3       0.72      0.73      0.73       392\n",
      "           4       0.80      0.84      0.82       385\n",
      "           5       0.84      0.77      0.81       395\n",
      "           6       0.75      0.85      0.80       390\n",
      "           7       0.91      0.88      0.90       396\n",
      "           8       0.97      0.95      0.96       398\n",
      "           9       0.91      0.92      0.92       397\n",
      "          10       0.93      0.97      0.95       399\n",
      "          11       0.94      0.92      0.93       396\n",
      "          12       0.75      0.78      0.77       393\n",
      "          13       0.88      0.86      0.87       396\n",
      "          14       0.88      0.93      0.90       394\n",
      "          15       0.80      0.91      0.85       398\n",
      "          16       0.73      0.90      0.81       364\n",
      "          17       0.97      0.88      0.92       376\n",
      "          18       0.83      0.60      0.69       310\n",
      "          19       0.80      0.47      0.59       251\n",
      "\n",
      "    accuracy                           0.83      7532\n",
      "   macro avg       0.83      0.82      0.82      7532\n",
      "weighted avg       0.83      0.83      0.83      7532\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Modele : SGD_classifier score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79       319\n",
      "           1       0.78      0.80      0.79       389\n",
      "           2       0.76      0.73      0.74       394\n",
      "           3       0.73      0.74      0.74       392\n",
      "           4       0.82      0.85      0.84       385\n",
      "           5       0.87      0.79      0.83       395\n",
      "           6       0.81      0.89      0.85       390\n",
      "           7       0.92      0.90      0.91       396\n",
      "           8       0.96      0.96      0.96       398\n",
      "           9       0.91      0.95      0.93       397\n",
      "          10       0.93      0.98      0.95       399\n",
      "          11       0.92      0.94      0.93       396\n",
      "          12       0.80      0.77      0.79       393\n",
      "          13       0.89      0.89      0.89       396\n",
      "          14       0.90      0.93      0.92       394\n",
      "          15       0.83      0.92      0.87       398\n",
      "          16       0.74      0.93      0.82       364\n",
      "          17       0.96      0.90      0.93       376\n",
      "          18       0.87      0.61      0.72       310\n",
      "          19       0.73      0.59      0.65       251\n",
      "\n",
      "    accuracy                           0.85      7532\n",
      "   macro avg       0.85      0.84      0.84      7532\n",
      "weighted avg       0.85      0.85      0.85      7532\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Modele : Linear SVC score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79       319\n",
      "           1       0.76      0.81      0.79       389\n",
      "           2       0.77      0.73      0.75       394\n",
      "           3       0.73      0.74      0.73       392\n",
      "           4       0.81      0.88      0.84       385\n",
      "           5       0.86      0.78      0.82       395\n",
      "           6       0.80      0.89      0.84       390\n",
      "           7       0.92      0.92      0.92       396\n",
      "           8       0.97      0.96      0.97       398\n",
      "           9       0.92      0.95      0.93       397\n",
      "          10       0.96      0.98      0.97       399\n",
      "          11       0.93      0.94      0.93       396\n",
      "          12       0.79      0.78      0.78       393\n",
      "          13       0.91      0.87      0.89       396\n",
      "          14       0.91      0.93      0.92       394\n",
      "          15       0.84      0.92      0.88       398\n",
      "          16       0.76      0.92      0.84       364\n",
      "          17       0.97      0.89      0.93       376\n",
      "          18       0.85      0.62      0.72       310\n",
      "          19       0.72      0.63      0.68       251\n",
      "\n",
      "    accuracy                           0.85      7532\n",
      "   macro avg       0.85      0.84      0.85      7532\n",
      "weighted avg       0.85      0.85      0.85      7532\n",
      " \n",
      "\n",
      "\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y713xh-trmrY",
    "colab_type": "text"
   },
   "source": [
    "## Results\n",
    "\n",
    "If we compare the scores in the three cases :\n",
    "\n",
    "* The lemming don't have a big impact on the scores. We don't have a big improvement in performance.\n",
    "* Removing the stops words and the punctuations improve\n",
    "\n",
    "* classes that have lower score have most of the time lower support value \n",
    "have lower scores. This can been explained by the fact that the algortihm can train on less example of this classe so he learn less pattern to recognize this classe compare to others. Notice that when we study the dataset distribution we see that topic 19 (religion 3.3%), 0 (atheism) and 18 (politics ) was the classe with less data. And we see that on this class the model have lower performance compare to other classes where the data quantity is close to the mean (5%).\n",
    "\n",
    "### Ideas\n",
    "[Handle imbalanced dataset](https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18)\n",
    "\n",
    "Resampling Techniques — Oversample minority class\n",
    "\n",
    "Note : we need to do train_test_split before. \n",
    "Oversampling before splitting the data can allow the exact same observations to be present in both the test and train sets. This can allow our model to simply memorize specific data points and cause overfitting and poor generalization to the test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nv-e78p2rfmp",
    "colab_type": "text"
   },
   "source": [
    "# Doc2Vec performance\n",
    "\n",
    "\n",
    "Now we are going to implement Doc2Vec on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xvif09SvOeyn",
    "colab_type": "code",
    "outputId": "a88fb56b-2034-4d2e-ed82-574998454216",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    }
   },
   "source": [
    "!pip install gensim "
   ],
   "execution_count": 78,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.3.2)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.17.4)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.10.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.14 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.13.14)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->smart-open>=1.2.1->gensim) (2.6.1)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbbEceO4O46g",
    "colab_type": "text"
   },
   "source": [
    "We are going to use gensim Doc2Vec. \n",
    "\n",
    "Doc2Vec technique is use to get a representation of a document words. \n",
    "A Document vector represent the text. \n",
    "\n",
    "We have already clean and tokenize the text with the prepareText function. \n",
    "Now we need to create a list of TaggedDocument.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4UGfYGUZPJTK",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "\n",
    "# create a tagged object \n",
    "\n",
    "taggedDocument = [TaggedDocument(doc, [tag]) for doc, tag in zip(x_train, newsgroups_train.target)]\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aXAvF6Vbfw6",
    "colab_type": "text"
   },
   "source": [
    "Note : TaggedDocument() take a string as document and a list of tag \n",
    "so : \n",
    "  * doc : String \n",
    "  * tag : [list of tag]"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xpXD6zQlRRBU",
    "colab_type": "code",
    "outputId": "feb35d26-dfc1-4ee1-bef0-863f8c7f5cac",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "taggedDocument[0].tags"
   ],
   "execution_count": 80,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[7]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 80
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KAMQcnoiRVM9",
    "colab_type": "code",
    "outputId": "698a0816-5bd4-4d87-f682-7bee4bba7c4a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "taggedDocument[0].words[1:10]"
   ],
   "execution_count": 81,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['lerxst@wam.umd.edu', '(', 'thing', ')', '\\n', 'subject', ':', 'car', '!']"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 81
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4Hnp0ozTzj0",
    "colab_type": "text"
   },
   "source": [
    "* If dm=0, distributed bag of words (PV-DBOW) is used; if dm=1,‘distributed memory’ (PV-DM) is used.\n",
    "* vector_size : 300- dimensional feature vectors. (In the research paper they use 400) \n",
    "\n",
    "* window (int, optional) – The maximum distance between the current and predicted word within a sentence.\n",
    "\n",
    "* min_count=2, ignores all words with total frequency lower than this.\n",
    "* negative=5 , specifies how many “noise words” should be drawn.\n",
    "* hs=0 , and negative is non-zero, negative sampling will be used.\n",
    "* sample=0 , the threshold for configuring which higher-frequency words are randomly down sampled.\n",
    "* workers=cores , use these many worker threads to train the model (=faster training with multicore machines)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rZElxYPETGmw",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "doc2vec = Doc2Vec(dm=1, vector_size=400, window=20, min_count=2, negative=5, hs=0, sample=0, workers=cores)\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ta24rL1taVGT",
    "colab_type": "text"
   },
   "source": [
    "Build a vocab from all the documents."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cScBfYscZng8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "doc2vec.build_vocab(taggedDocument)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IQJOAMLHaZH-",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "doc2vec.train(taggedDocument, total_examples=len(taggedDocument), epochs=10)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_RYdNr7dhWY",
    "colab_type": "text"
   },
   "source": [
    "### Vec_for_learning :\n",
    "\n",
    "The inference tries to fit a later example into a frozen model, and so if you re-present the same document, it should \n",
    "wind up 'close' to the vector that the same document induced in multi-pass bulk training. But how 'close' would depend \n",
    "on a lot of things. The information in the PV paper about parameter choices is limited.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BN8DTr3-dgaH",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "def vec_for_learning(doc2vec_model, tagged_docs):\n",
    "    targets, regressors = zip(*[(doc.tags[0], doc2vec_model.infer_vector(doc.words, steps=20)) for doc in tqdm(tagged_docs)])\n",
    "    return targets, regressors"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTMQt6y1_M7w",
    "colab_type": "text"
   },
   "source": [
    " targets, regressors = zip(*[(doc.tags[0], doc2vec_model.infer_vector(doc.words, steps=20)) for doc in tagged_docs])\n",
    "\n",
    " At this line we use Zip to iter on an array of tuple that contains the tag associated to the i document and the Document vector that represent the i ème document. \n",
    "\n",
    "targets : contains the tags \n",
    "regressors : contains all the vector infered associated to a document.\n",
    "\n",
    "demonstration :\n",
    "\n",
    "array = [(1, 'a'), (2, 'b'), (3, 'c')]\n",
    "\n",
    "target, reg = zip(*array)\n",
    "\n",
    "print(target, reg)\n",
    "\n",
    "==> output :\n",
    "(1, 2, 3) ('a', 'b', 'c') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8dbNLeXhYa9",
    "colab_type": "text"
   },
   "source": [
    "Test have not been prepared. So we need to do the same operation that on the training data on the test data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "majCVHk0hn3a",
    "colab_type": "code",
    "outputId": "78c596c2-7fd6-40e8-86ce-7a3ba368c992",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "\n",
    "test_data = newsgroups_test.data.copy()\n",
    "\n",
    "for i in range(0, len(test_data)) :\n",
    "  test_data[i] = prepareText(test_data[i])\n",
    "\n",
    "test_data[0]"
   ],
   "execution_count": 86,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[':',\n",
       " 'v064mb9k@ubvmsd.cc.buffalo.edu',\n",
       " '(',\n",
       " 'neil',\n",
       " 'b.',\n",
       " 'gandler',\n",
       " ')',\n",
       " '\\n',\n",
       " 'subject',\n",
       " ':',\n",
       " 'need',\n",
       " 'info',\n",
       " '88',\n",
       " '-',\n",
       " '89',\n",
       " 'bonneville',\n",
       " '\\n',\n",
       " 'organization',\n",
       " ':',\n",
       " 'university',\n",
       " 'buffalo',\n",
       " '\\n',\n",
       " 'line',\n",
       " ':',\n",
       " '10',\n",
       " '\\n',\n",
       " 'news',\n",
       " '-',\n",
       " 'software',\n",
       " ':',\n",
       " 'vax',\n",
       " '/',\n",
       " 'vms',\n",
       " 'vnews',\n",
       " '1.41',\n",
       " '\\n',\n",
       " 'nntp',\n",
       " '-',\n",
       " 'posting',\n",
       " '-',\n",
       " 'host',\n",
       " ':',\n",
       " 'ubvmsd.cc.buffalo.edu',\n",
       " '\\n\\n\\n ',\n",
       " 'little',\n",
       " 'confused',\n",
       " 'model',\n",
       " '88',\n",
       " '-',\n",
       " '89',\n",
       " 'bonneville',\n",
       " '.',\n",
       " '\\n',\n",
       " 'hear',\n",
       " 'le',\n",
       " 'se',\n",
       " 'lse',\n",
       " 'sse',\n",
       " 'ssei',\n",
       " '.',\n",
       " 'tell',\n",
       " '\\n',\n",
       " 'difference',\n",
       " 'far',\n",
       " 'feature',\n",
       " 'performance',\n",
       " '.',\n",
       " 'curious',\n",
       " '\\n',\n",
       " 'know',\n",
       " 'book',\n",
       " 'value',\n",
       " 'prefereably',\n",
       " '89',\n",
       " 'model',\n",
       " '.',\n",
       " '\\n',\n",
       " 'book',\n",
       " 'value',\n",
       " 'usually',\n",
       " '.',\n",
       " 'word',\n",
       " '\\n',\n",
       " 'demand',\n",
       " 'time',\n",
       " 'year',\n",
       " '.',\n",
       " 'hear',\n",
       " 'mid',\n",
       " '-',\n",
       " 'spring',\n",
       " '\\n',\n",
       " 'early',\n",
       " 'summer',\n",
       " 'good',\n",
       " 'time',\n",
       " 'buy',\n",
       " '.',\n",
       " '\\n\\n\\t\\t\\t',\n",
       " 'neil',\n",
       " 'gandler',\n",
       " '\\n']"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 86
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gRx5JXqJh-G9",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "taggedTestDocument = [TaggedDocument(doc, [tag]) for doc, tag in zip(test_data, newsgroups_test.target)]"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhnWERANCED2",
    "colab_type": "text"
   },
   "source": [
    "# Training & Testing\n",
    "\n",
    "We remove Naives bayes because we can not use it on negative input. And the Doc2Vec contains negative values."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6voTKPe4dq6L",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.metrics import classification_report \n",
    "modeles = {\"logistic regression\": LogisticRegression(), \"SGD_classifier\": SGDClassifier(), \"Linear SVC\": LinearSVC()}"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HXkVR259Ivno",
    "colab_type": "code",
    "outputId": "593aa1d3-4f94-44b0-a653-be6ebd267c51",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    }
   },
   "source": [
    "y_train, x_train = vec_for_learning(doc2vec, taggedDocument)\n",
    "y_test, x_test = vec_for_learning(doc2vec, taggedTestDocument)\n"
   ],
   "execution_count": 89,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 11314/11314 [05:39<00:00, 33.34it/s]\n",
      "100%|██████████| 7532/7532 [03:40<00:00, 34.16it/s]\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GJpmlrizGHq1",
    "colab_type": "code",
    "outputId": "674f7bcd-c0d6-4af0-e407-07d70e01070e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "#testing \n",
    "for key in tqdm(modeles):\n",
    "  modeles[key].fit(x_train, y_train)  \n",
    "  \n",
    "  predicted = modeles[key].predict(x_test)\n",
    "  \n",
    "  # F1-Score & Recall & Precision \n",
    "  score = classification_report(predicted, y_test, labels=classes)\n",
    "  \n",
    "  print(f\"Modele : {key} score : {score}\")"
   ],
   "execution_count": 90,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      " 33%|███▎      | 1/3 [01:04<02:08, 64.26s/it]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Modele : logistic regression score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69       346\n",
      "           1       0.67      0.66      0.67       395\n",
      "           2       0.57      0.62      0.59       359\n",
      "           3       0.67      0.61      0.64       429\n",
      "           4       0.78      0.80      0.79       374\n",
      "           5       0.74      0.76      0.75       386\n",
      "           6       0.68      0.58      0.63       458\n",
      "           7       0.85      0.83      0.84       405\n",
      "           8       0.92      0.92      0.92       400\n",
      "           9       0.92      0.88      0.90       416\n",
      "          10       0.92      0.92      0.92       402\n",
      "          11       0.87      0.83      0.85       415\n",
      "          12       0.65      0.71      0.68       362\n",
      "          13       0.76      0.83      0.80       362\n",
      "          14       0.85      0.86      0.85       390\n",
      "          15       0.85      0.76      0.80       447\n",
      "          16       0.79      0.72      0.75       399\n",
      "          17       0.83      0.89      0.86       353\n",
      "          18       0.47      0.68      0.56       217\n",
      "          19       0.48      0.55      0.51       217\n",
      "\n",
      "    accuracy                           0.76      7532\n",
      "   macro avg       0.75      0.75      0.75      7532\n",
      "weighted avg       0.76      0.76      0.76      7532\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\r 67%|██████▋   | 2/3 [01:12<00:47, 47.45s/it]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Modele : SGD_classifier score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.80      0.65       219\n",
      "           1       0.70      0.49      0.58       561\n",
      "           2       0.51      0.59      0.54       340\n",
      "           3       0.51      0.70      0.59       286\n",
      "           4       0.75      0.77      0.76       377\n",
      "           5       0.75      0.65      0.69       457\n",
      "           6       0.47      0.79      0.59       233\n",
      "           7       0.82      0.75      0.79       432\n",
      "           8       0.95      0.76      0.84       497\n",
      "           9       0.84      0.91      0.87       369\n",
      "          10       0.93      0.80      0.86       463\n",
      "          11       0.85      0.82      0.84       411\n",
      "          12       0.58      0.70      0.63       322\n",
      "          13       0.76      0.78      0.77       387\n",
      "          14       0.86      0.78      0.82       433\n",
      "          15       0.78      0.84      0.81       370\n",
      "          16       0.78      0.65      0.71       438\n",
      "          17       0.76      0.95      0.85       303\n",
      "          18       0.61      0.41      0.49       462\n",
      "          19       0.43      0.63      0.51       172\n",
      "\n",
      "    accuracy                           0.72      7532\n",
      "   macro avg       0.71      0.73      0.71      7532\n",
      "weighted avg       0.74      0.72      0.72      7532\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "\r100%|██████████| 3/3 [01:42<00:00, 42.31s/it]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Modele : Linear SVC score :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.67       343\n",
      "           1       0.64      0.68      0.66       365\n",
      "           2       0.55      0.60      0.58       360\n",
      "           3       0.64      0.57      0.60       438\n",
      "           4       0.78      0.78      0.78       389\n",
      "           5       0.73      0.75      0.74       384\n",
      "           6       0.67      0.59      0.63       444\n",
      "           7       0.83      0.82      0.83       399\n",
      "           8       0.92      0.88      0.90       418\n",
      "           9       0.90      0.86      0.88       417\n",
      "          10       0.93      0.89      0.91       414\n",
      "          11       0.86      0.82      0.84       419\n",
      "          12       0.63      0.69      0.66       357\n",
      "          13       0.76      0.83      0.79       365\n",
      "          14       0.85      0.84      0.84       396\n",
      "          15       0.83      0.76      0.80       436\n",
      "          16       0.78      0.69      0.73       409\n",
      "          17       0.80      0.88      0.84       345\n",
      "          18       0.48      0.68      0.56       218\n",
      "          19       0.48      0.56      0.51       216\n",
      "\n",
      "    accuracy                           0.75      7532\n",
      "   macro avg       0.74      0.74      0.74      7532\n",
      "weighted avg       0.75      0.75      0.75      7532\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WktFvWop5TEo",
    "colab_type": "text"
   },
   "source": [
    "# TF-IDF vs Doc2Vec \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mh41Zn9m7H3y",
    "colab_type": "text"
   },
   "source": [
    "# Idea\n",
    "\n",
    "* Use grid search to search better hyper parameter.\n",
    "* increase the window size for the Doc2Vec.\n",
    "* reduce the vector_size to reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtvvK3DECTav",
    "colab_type": "text"
   },
   "source": [
    "# Size from which our model provided good results\n",
    "\n",
    "test on 4 size :\n",
    "\n",
    "* 1 millions words \n",
    "* 500k words \n",
    "* 100k words \n",
    "* 1k words \n",
    "\n",
    "The first step is to construct a function that count the number of words and create a subdataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7umSeUwcKgPs",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "outputId": "c1f8d049-9213-4bf9-f375-5a4614756709"
   },
   "source": [
    "for i in range(10):\n",
    "  rand = randrange(0, 1000)\n",
    "  print(rand)"
   ],
   "execution_count": 103,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "82\n",
      "172\n",
      "134\n",
      "600\n",
      "952\n",
      "326\n",
      "362\n",
      "425\n",
      "12\n",
      "346\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YMNliIBHL7xi",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "outputId": "706de85e-2bce-4dd9-934f-c4926fea1f3d"
   },
   "source": [
    "from random import randrange\n",
    "\n",
    "# we can take all the data and make a array of size 20 that contains Dataset by classe \n",
    "df = pd.DataFrame({'Text' : newsgroups_train.data, 'target' : newsgroups_train.target})\n",
    "df.head()"
   ],
   "execution_count": 105,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  target\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 105
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E0PVKLOsL_mS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "28Npi_a7DezD",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "def countWordAndCreateDataset(datas, tags, nwords=100000):\n",
    "  dataset = [ ]\n",
    "  dataset_tag = []\n",
    "  word_counter = 0\n",
    "  while word_counter <= nwords:\n",
    "    for target in range(0, len(newsgroups_train.target_names) -1):\n",
    "      data = df[df['target'] == target]\n",
    "      randindex = randrange(0, len(data))\n",
    "      dataset.append(datas[randindex])\n",
    "      dataset_tag.append(tags[target])\n",
    "      word_counter += len(datas[randindex].split(' '))\n",
    "  print(f\"Return a dataset of that contains {word_counter} words\")\n",
    "  return (dataset, dataset_tag)\n",
    "  \n",
    "  "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hqR2G2eK04n",
    "colab_type": "text"
   },
   "source": [
    "This selection function must create a balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EZN5Km1bVX56",
    "colab_type": "code",
    "outputId": "e83b7ad5-1f43-4869-b147-de26f068d242",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    }
   },
   "source": [
    "sizes = [10000000, 5000000, 1000000, 600000, 500000, 10000, 5000]\n",
    "dataset_dict = {}\n",
    "for size in sizes:\n",
    "  dataset_target_tuple = countWordAndCreateDataset(datas=newsgroups_train.data, tags=newsgroups_train.target, nwords=size)\n",
    "  dataset_dict[size] = dataset_target_tuple"
   ],
   "execution_count": 107,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Return a dataset of that contains 10001390 words\n",
      "Return a dataset of that contains 5003730 words\n",
      "Return a dataset of that contains 1005048 words\n",
      "Return a dataset of that contains 602152 words\n",
      "Return a dataset of that contains 503654 words\n",
      "Return a dataset of that contains 12423 words\n",
      "Return a dataset of that contains 6345 words\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g8FNGcfrSBnf",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "03234f61-7405-44f9-9f21-b02be47fd4a4"
   },
   "source": [
    "len(dataset_dict[1000000][0])"
   ],
   "execution_count": 108,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3553"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 108
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQu8QY0zTBzu",
    "colab_type": "text"
   },
   "source": [
    "We have now 7 datasets of differents size that are well balanced. We are going to look at wich number of words in the corpus the dataset perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm18HUnXSdpv",
    "colab_type": "text"
   },
   "source": [
    "contains our 7 datasets of differents size. Let's  clean those dataset and train TFIDF+ML_modele on them."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oTllFF35U0Lo",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# We need to train different model for each dataset \n",
    "modeles_dict = {}\n",
    "for key in dataset_dict:\n",
    "  modeles_dict[key] =  {\"naives\":naives_clf, \"logistic regression\": log_clf, \"SGD_classifier\":sgd_clf, \"Linear SVC\":svc_clf} \n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3W3ZLgAZOl4-",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "outputId": "b10af5b1-12d5-48fb-d063-3a6ac84c85be"
   },
   "source": [
    "\n",
    "for dataset_key in dataset_dict:\n",
    "  print(f\"Dataset of size : {dataset_key} \\n\\n\")\n",
    "  modeles = modeles_dict[dataset_key]\n",
    "  for key in modeles:\n",
    "    modeles[key].fit(dataset_dict[dataset_key][0], dataset_dict[dataset_key][1])\n",
    "    predicted = modeles[key].predict(newsgroups_test.data)\n",
    "    score = precision_recall_fscore_support(newsgroups_test.target, predicted, average='weighted')\n",
    "    print(f\"Modele : {key} score : {score} \\n\\n\\n\")"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Dataset of size : 10000000 \n",
      "\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Modele : naives score : (0.009995144526211973, 0.05111524163568773, 0.005239470962763271, None) \n",
      "\n",
      "\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Modele : logistic regression score : (0.002615893663397551, 0.05111524163568773, 0.004977078409140055, None) \n",
      "\n",
      "\n",
      "\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Modele : SGD_classifier score : (0.03543332023909441, 0.05616038236856081, 0.029820277692959234, None) \n",
      "\n",
      "\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHUCsAn1eIYM",
    "colab_type": "text"
   },
   "source": [
    "do the same operation with Doc2Vec "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2NsSKZS6eIAz",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "outputId": "3ae516e8-5238-41dd-ea99-8161d993c368"
   },
   "source": [
    "def prepareDataset(dataset):\n",
    "  for i in tqdm(range(0, len(dataset)-1)):\n",
    "    dataset[i] = prepareText(dataset[i])\n",
    "    \n",
    "for key in dataset_dict:\n",
    "  prepareDataset(dataset=dataset_dict[key][0])"
   ],
   "execution_count": 95,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 11312/11312 [13:07<00:00, 14.36it/s]\n",
      "100%|██████████| 11312/11312 [13:04<00:00, 14.43it/s]\n",
      "100%|██████████| 3286/3286 [03:40<00:00,  4.08it/s]\n",
      "100%|██████████| 1949/1949 [02:12<00:00, 14.68it/s]\n",
      "100%|██████████| 1584/1584 [01:49<00:00, 14.43it/s]\n",
      "100%|██████████| 35/35 [00:02<00:00, 15.08it/s]\n",
      "100%|██████████| 17/17 [00:01<00:00, 14.42it/s]\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLUYwAYf5vEA",
    "colab_type": "text"
   },
   "source": [
    "# Doc2Vec similarity\n",
    "\n",
    "We are going to use Doc2Vec similarity method to find similar document. \n",
    "\n",
    "* We can use a a word embedding to find similar Document Vector to a word.\n",
    "\n",
    "exp : word = Sport \n",
    "    - If we ask all the Document similar to \"Sport\" normaly we should get all the Document vector close to \"Sport\"."
   ]
  }
 ]
}